---
wave: 1
depends_on: 16-testing-infrastructure
files_modified:
  - tests/test_system/test_startup.py
  - tests/test_system/test_configuration.py
autonomous: true
---

# Plan 17-01: System Startup and Configuration Tests

## Objective

Create comprehensive system tests that verify the bot can start up correctly, connect to the database, load all services, and handle configuration validation. These tests ensure the foundational infrastructure works before testing higher-level features.

## Context

Phase 16 completed the testing infrastructure with pytest-asyncio, fixtures, and in-memory database. Now we need to build on that foundation to test the actual system startup and configuration loading.

**Current State:**
- Bot has complex startup sequence in `main.py` with database initialization, migration runner, and background tasks
- Config service uses singleton pattern with BotConfig (id=1)
- Multiple services loaded via ServiceContainer with lazy loading
- Health check endpoint for Railway monitoring

**Why This Matters:**
- System startup is the foundation - if it fails, nothing works
- Configuration bugs are common and hard to catch without automated tests
- Early failure detection saves debugging time downstream

## Success Criteria

1. Test verifies bot initialization completes without errors
2. Test verifies database connection and migration runner
3. Test verifies all services load via ServiceContainer
4. Test verifies configuration validation and defaults
5. Tests cover both valid and invalid configuration scenarios

## Tasks

### Task 1: Create System Startup Test Suite

**File:** `tests/test_system/test_startup.py`

Create tests for bot startup sequence:

```python
# Test 1: Database initialization
async def test_database_initialization(test_db):
    """Verify database tables are created correctly."""
    from bot.database.base import Base
    from sqlalchemy import inspect

    inspector = inspect(test_db.bind)
    tables = inspector.get_table_names()

    # Verify all 9 tables exist
    expected_tables = [
        'bot_config', 'vip_subscribers', 'invitation_tokens',
        'free_channel_requests', 'content_packages', 'user_interests',
        'users', 'user_role_change_log', 'pricing_tiers'
    ]
    for table in expected_tables:
        assert table in tables, f"Table {table} not found"

# Test 2: ServiceContainer lazy loading
async def test_service_container_lazy_loading(container):
    """Verify all services load correctly."""
    # Test subscription service
    subscription = container.subscription
    assert subscription is not None
    assert hasattr(subscription, 'generate_vip_token')

    # Test channel service
    channel = container.channel
    assert channel is not None
    assert hasattr(channel, 'setup_vip_channel')

    # Test config service
    config = container.config
    assert config is not None
    assert hasattr(config, 'get_config')

    # Test role detection service
    role_detection = container.role_detection
    assert role_detection is not None
    assert hasattr(role_detection, 'get_user_role')

    # Test content service
    content = container.content
    assert content is not None
    assert hasattr(content, 'create_package')

    # Test interest service
    interest = container.interest
    assert interest is not None
    assert hasattr(interest, 'create_interest')

    # Test user management service
    user_management = container.user_management
    assert user_management is not None
    assert hasattr(user_management, 'get_user_info')

    # Verify preload functionality
    loaded_before = container.get_loaded_services()
    container.preload_critical_services()
    loaded_after = container.get_loaded_services()
    assert len(loaded_after) >= len(loaded_before)

# Test 3: BotConfig singleton seeding
async def test_botconfig_singleton_seeding(test_session):
    """Verify BotConfig is auto-seeded with defaults."""
    from bot.database.models import BotConfig
    from bot.services.config import ConfigService

    config_service = ConfigService(test_session)

    # First access should create singleton
    config = await config_service.get_config()
    assert config is not None
    assert config.id == 1

    # Verify default values
    assert config.wait_time >= 1
    assert config.vip_reactions is not None
    assert len(config.vip_reactions) > 0
    assert config.free_reactions is not None
    assert len(config.free_reactions) > 0

# Test 4: Background tasks initialization
async def test_background_tasks_initialization(mock_bot):
    """Verify background tasks scheduler initializes."""
    from bot.background.tasks import start_background_tasks, stop_background_tasks

    # Start background tasks
    start_background_tasks(mock_bot)

    # Verify scheduler is running
    from bot.background.tasks import scheduler
    assert scheduler.running

    # Stop background tasks
    stop_background_tasks()
```

### Task 2: Create Configuration Test Suite

**File:** `tests/test_system/test_configuration.py`

Create tests for configuration management:

```python
# Test 1: Configuration validation - fully configured
async def test_config_validation_fully_configured(container):
    """Verify configuration status detection."""
    # Set all required config values
    await container.config.set_wait_time(5)
    await container.config.set_vip_channel_id("-1001234567890")
    await container.config.set_free_channel_id("-1000987654321")

    # Check configuration status
    status = await container.config.get_config_status()

    assert status["is_configured"] is True
    assert len(status.get("missing", [])) == 0

# Test 2: Configuration validation - missing items
async def test_config_validation_missing_items(container):
    """Verify missing configuration detection."""
    # Clear VIP channel ID
    await container.config.set_vip_channel_id(None)

    # Check configuration status
    status = await container.config.get_config_status()

    assert status["is_configured"] is False
    assert "vip_channel_id" in status.get("missing", [])

# Test 3: Configuration setters with validation
async def test_config_setters_validation(container):
    """Verify configuration setters validate input."""
    import pytest

    # Test invalid wait_time (must be >= 1)
    with pytest.raises(ValueError):
        await container.config.set_wait_time(0)

    with pytest.raises(ValueError):
        await container.config.set_wait_time(-5)

    # Test invalid reactions (must be 1-10)
    with pytest.raises(ValueError):
        await container.config.set_vip_reactions([])

    with pytest.raises(ValueError):
        await container.config.set_vip_reactions(["a"] * 11)

    # Test invalid subscription fees (must be positive)
    with pytest.raises(ValueError):
        await container.config.set_subscription_fees({
            "vip_monthly": -10.0
        })

# Test 4: Configuration summary generation
async def test_config_summary_generation(container):
    """Verify configuration summary for admin panel."""
    # Set some config values
    await container.config.set_wait_time(10)
    await container.config.set_vip_channel_id("-1001234567890")

    # Get summary
    summary = await container.config.get_config_summary()

    assert summary is not None
    assert "wait_time" in summary.lower() or "tiempo" in summary.lower()
    assert "-1001234567890" in summary or "VIP" in summary

# Test 5: Configuration reset to defaults
async def test_config_reset_to_defaults(container):
    """Verify configuration can be reset."""
    # Modify config
    await container.config.set_wait_time(999)

    # Reset to defaults
    await container.config.reset_to_defaults()

    # Verify reset
    config = await container.config.get_config()
    assert config.wait_time != 999  # Should be default value
```

### Task 3: Create Health Check Test

**File:** `tests/test_system/test_health.py`

Create tests for health check endpoint:

```python
# Test 1: Health check with healthy database
async def test_health_check_healthy():
    """Verify health check returns 200 when database is healthy."""
    from bot.health.app import app
    from httpx import AsyncClient, ASGITransport

    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        response = await client.get("/health")

    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert "database" in data
    assert data["database"]["status"] == "connected"

# Test 2: Health check with database error
async def test_health_check_database_error(test_session, monkeypatch):
    """Verify health check returns 503 when database fails."""
    from bot.health.app import app
    from httpx import AsyncClient, ASGITransport
    from unittest.mock import AsyncMock

    # Mock database check to raise exception
    async def mock_check():
        raise Exception("Database connection failed")

    # Patch the health check function
    import bot.health.endpoints
    monkeypatch.setattr(bot.health.endpoints, "check_database_health", mock_check)

    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        response = await client.get("/health")

    assert response.status_code == 503
    data = response.json()
    assert data["status"] == "unhealthy"
    assert data["database"]["status"] == "error"
```

## Verification

**Manual Verification:**
1. Run `pytest tests/test_system/ -v` and verify all tests pass
2. Run `pytest tests/test_system/ --cov=bot --cov-report=term-missing` and verify coverage
3. Run `pytest tests/test_system/test_startup.py::test_service_container_lazy_loading -v` to verify service loading

**Automated Verification:**
- All tests pass without errors
- Coverage for system startup and configuration code > 80%
- Tests complete in < 30 seconds

## Anti-Patterns to Avoid

1. **Don't mock the database** - Use test_db fixture for real DB operations
2. **Don't test implementation details** - Test observable behavior (services load, config validates)
3. **Don't ignore error cases** - Test both success and failure scenarios
4. **Don't make tests dependent on external services** - All tests should work offline
5. **Don't skip service loading tests** - Verify all 11 services load correctly

## Notes

- Use `container_with_preload` fixture when testing service interactions
- Use `monkeypatch` fixture for mocking environment variables
- Use `pytest.raises` for exception testing
- Keep tests fast - no external API calls
- Tests should be independent and can run in any order

## References

- Phase 16 testing infrastructure: `.planning/phases/16-testing-infrastructure/`
- ServiceContainer implementation: `bot/services/container.py`
- ConfigService implementation: `bot/services/config.py`
- Health check implementation: `bot/health/`
